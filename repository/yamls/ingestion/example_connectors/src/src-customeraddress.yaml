apiVersion: "kafka.strimzi.io/v1beta2"
kind: "KafkaConnector"
metadata:
  name: "src-sqlserver-jdbc-sampledb-customeraddress-avro-05b34d17"
  labels:
    strimzi.io/cluster: edh
spec:
  class: io.confluent.connect.jdbc.JdbcSourceConnector
  tasksMax: 2
  config:
    key.converter: "io.confluent.connect.avro.AvroConverter"
    key.converter.schema.registry.url: "http://schema-registry-cp-schema-registry:8081"
    value.converter: "io.confluent.connect.avro.AvroConverter"
    value.converter.schema.registry.url: "http://schema-registry-cp-schema-registry:8081"
    connection.url: "jdbc:sqlserver://sampledb.mssql.somee.com:1433;databaseName=sampledb"
    connection.user: "vsvale_SQLLogin_1"
    connection.password: "41y12q7yhx"
    connection.attempts: "2"
    topic.prefix: "src-example-customeraddress"
    mode: "timestamp+incrementing"
    incrementing.column.name: "Custom_Key"
    timestamp.column.name: "Custom_TS"
    query: "select t.* from (select *, CONVERT(BIGINT,CONCAT(LTRIM(STR(CustomerID,10)),LTRIM(STR(AddressID,10)))) as Custom_Key, CONVERT (DATETIME2, ModifiedDate) as Custom_TS from sampledb.SalesLT.CustomerAddress) as t"
    validate.non.null: "false"
    transforms: "createKey,extractInt,InsertTopic,InsertSourceDetails"
    transforms.createKey.type: "org.apache.kafka.connect.transforms.ValueToKey"
    transforms.createKey.fields: "Custom_Key"
    transforms.extractInt.type: "org.apache.kafka.connect.transforms.ExtractField$Key"
    transforms.extractInt.field: "Custom_Key"
    transforms.InsertTopic.type: "org.apache.kafka.connect.transforms.InsertField$Value"
    transforms.InsertTopic.topic.field: "messagetopic"
    transforms.InsertSourceDetails.type: "org.apache.kafka.connect.transforms.InsertField$Value"
    transforms.InsertSourceDetails.static.field: "messagesource"
    transforms.InsertSourceDetails.static.value: "sqlserver-sampledb-SalesLT"